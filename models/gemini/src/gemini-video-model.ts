import type {
  AgentInvokeOptions,
  FileUnionContent,
  VideoModelInput,
  VideoModelOptions,
  VideoModelOutput,
} from "@aigne/core";
import { fileUnionContentSchema, VideoModel, videoModelInputSchema } from "@aigne/core";
import { logger } from "@aigne/core/utils/logger.js";
import { checkArguments } from "@aigne/core/utils/type-utils.js";
import { nodejs } from "@aigne/platform-helpers/nodejs/index.js";
import { type GenerateVideosParameters, GoogleGenAI } from "@google/genai";
import { type ZodType, z } from "zod";
import { waitFileSizeStable } from "./utils.js";

const DEFAULT_MODEL = "veo-3.1-generate-preview";
const DEFAULT_SECONDS = 8;

/**
 * Input options for Gemini Video Model
 */
export interface GeminiVideoModelInput extends VideoModelInput {
  /**
   * Text describing content that should not appear in the video
   */
  negativePrompt?: string;

  /**
   * Aspect ratio of the video
   *
   * Veo 3.1: "16:9" (default, 720p and 1080p), "9:16" (720p and 1080p)
   * Veo 3: "16:9" (default, 720p and 1080p), "9:16" (720p and 1080p)
   */
  aspectRatio?: "16:9" | "9:16";

  /**
   * Resolution of the video
   *
   * Veo 3.1: "720p" (default), "1080p" (only supports 8 seconds duration)
   * Veo 3: "720p" (default), "1080p" (16:9 only)
   */
  size?: "720p" | "1080p";

  /**
   * Duration of the generated video in seconds
   *
   * Veo 3.1: "4", "6", "8"
   * Veo 3: "4", "6", "8"
   */
  seconds?: "4" | "6" | "8";

  /**
   * Control person generation
   *
   * For text-to-video and image-to-video:
   * - Veo 3.1: "allow_all" for image-to-video, frame interpolation and reference images; only "allow_adult" for text-to-video
   * - Veo 3: "allow_all" for image-to-video; only "allow_adult" for text-to-video
   * - Veo 2: "allow_all", "allow_adult", "dont_allow"
   */
  personGeneration?: string;

  /**
   * Last frame for video generation (frame interpolation)
   */
  lastFrame?: FileUnionContent;

  /**
   * Reference images for video generation
   * Only supported in Veo 3.1 models
   */
  referenceImages?: FileUnionContent[];
}

/**
 * Output from Gemini Video Model
 */
export interface GeminiVideoModelOutput extends VideoModelOutput {}

/**
 * Configuration options for Gemini Video Model
 */
export interface GeminiVideoModelOptions
  extends VideoModelOptions<GeminiVideoModelInput, GeminiVideoModelOutput> {
  /**
   * API key for Gemini API
   *
   * If not provided, will look for GEMINI_API_KEY in environment variables
   */
  apiKey?: string;

  /**
   * Base URL for Gemini API
   *
   * Useful for proxies or alternate endpoints
   */
  baseURL?: string;

  /**
   * Gemini model to use
   *
   * Defaults to 'veo-3.1-generate-preview'
   */
  model?: string;

  /**
   * Additional model options to control behavior
   */
  modelOptions?: Omit<Partial<GeminiVideoModelInput>, "model">;

  /**
   * Client options for Gemini API
   */
  clientOptions?: Record<string, any>;

  /**
   * Polling interval in milliseconds for checking video generation status
   *
   * Defaults to 10000ms (10 seconds)
   */
  pollingInterval?: number;
}

const geminiVideoModelInputSchema: ZodType<GeminiVideoModelInput> = videoModelInputSchema.extend({
  negativePrompt: z.string().optional(),
  aspectRatio: z.enum(["16:9", "9:16"]).optional(),
  size: z.enum(["720p", "1080p"]).optional(),
  seconds: z.enum(["4", "6", "8"]).optional(),
  personGeneration: z.string().optional(),
  lastFrame: fileUnionContentSchema.optional(),
  referenceImages: fileUnionContentSchema.array().optional(),
});

const geminiVideoModelOptionsSchema = z.object({
  apiKey: z.string().optional(),
  baseURL: z.string().optional(),
  model: z.string().optional(),
  modelOptions: z.object({}).optional(),
  clientOptions: z.object({}).optional(),
  pollingInterval: z.number().optional(),
});

export class GeminiVideoModel extends VideoModel<GeminiVideoModelInput, GeminiVideoModelOutput> {
  constructor(public override options?: GeminiVideoModelOptions) {
    super({
      ...options,
      description: options?.description ?? "Generate videos using Google Gemini Veo models",
      inputSchema: geminiVideoModelInputSchema,
    });

    if (options) checkArguments(this.name, geminiVideoModelOptionsSchema, options);
  }

  /**
   * @hidden
   */
  protected _client?: GoogleGenAI;

  protected apiKeyEnvName = "GEMINI_API_KEY";

  get client() {
    const { apiKey } = this.credential;
    if (!apiKey)
      throw new Error(
        `${this.name} requires an API key. Please provide it via \`options.apiKey\`, or set the \`${this.apiKeyEnvName}\` environment variable`,
      );

    this._client ??= new GoogleGenAI({ apiKey, ...this.options?.clientOptions });
    return this._client;
  }

  override get credential() {
    return {
      url: this.options?.baseURL || process.env.GEMINI_BASE_URL,
      apiKey: this.options?.apiKey || process.env[this.apiKeyEnvName],
      model: this.options?.model || DEFAULT_MODEL,
    };
  }

  get modelOptions() {
    return this.options?.modelOptions;
  }

  async downloadToFile(
    dir: string,
    videoId: string,
    videoFile: { uri?: string; videoBytes?: any },
  ): Promise<string> {
    logger.debug("Downloading video content...");
    const localPath = nodejs.path.join(dir, `${videoId}.mp4`);
    await this.client.files.download({ file: videoFile, downloadPath: localPath });
    logger.debug(`Generated video saved to ${localPath}`);

    await waitFileSizeStable(localPath);

    const buffer = await nodejs.fs.readFile(localPath);
    return buffer.toString("base64");
  }

  override async process(
    input: GeminiVideoModelInput,
    options: AgentInvokeOptions,
  ): Promise<GeminiVideoModelOutput> {
    const model = input.model ?? input.modelOptions?.model ?? this.credential.model;
    const mergedInput = { ...this.modelOptions, ...input };

    if (mergedInput.referenceImages && !model.includes("veo-3.1")) {
      throw new Error("referenceImages is only supported in Veo 3.1 models");
    }

    const config: GenerateVideosParameters["config"] = {};
    if (mergedInput.negativePrompt) config.negativePrompt = mergedInput.negativePrompt;
    if (mergedInput.aspectRatio) config.aspectRatio = mergedInput.aspectRatio;
    if (mergedInput.size) config.resolution = mergedInput.size;
    if (mergedInput.seconds) config.durationSeconds = parseInt(mergedInput.seconds, 10);
    if (mergedInput.personGeneration) config.personGeneration = mergedInput.personGeneration;
    if (mergedInput.lastFrame) {
      config.lastFrame = await this.transformFileType("file", mergedInput.lastFrame).then(
        (file) => {
          return {
            imageBytes: file.data,
            mimeType: file.mimeType,
          };
        },
      );
    }

    if (mergedInput.referenceImages) {
      config.referenceImages = await Promise.all(
        mergedInput.referenceImages.map(async (image) => {
          return await this.transformFileType("file", image).then((file) => {
            return {
              image: {
                imageBytes: file.data,
                mimeType: file.mimeType,
              },
            };
          });
        }),
      );
    }

    const params: GenerateVideosParameters = {
      model,
      prompt: mergedInput.prompt,
      config,
    };

    if (mergedInput.image) {
      params.image = await this.transformFileType("file", mergedInput.image).then((file) => {
        return {
          imageBytes: file.data,
          mimeType: file.mimeType,
        };
      });
    }

    // Start video generation
    let operation = await this.client.models.generateVideos(params);
    logger.debug("Video generation started...");

    // Poll operation status until complete
    const pollingInterval = this.options?.pollingInterval ?? 10000;
    while (!operation.done) {
      logger.debug("Waiting for video generation to complete...");
      await new Promise((resolve) => setTimeout(resolve, pollingInterval));
      operation = await this.client.operations.getVideosOperation({ operation });
    }

    if (!operation.response?.generatedVideos?.[0]?.video) {
      throw new Error("Video generation failed: No video generated");
    }

    // Download the generated video
    const generatedVideo = operation.response.generatedVideos[0];
    const videoFile = generatedVideo.video;

    if (!videoFile) {
      throw new Error("Video generation failed: No video file returned");
    }

    // Save to temporary directory
    const dir = nodejs.path.join(nodejs.os.tmpdir(), options?.context?.id || "");
    await nodejs.fs.mkdir(dir, { recursive: true });

    const videoId = Date.now().toString();

    return {
      videos: [
        {
          type: "file",
          data: await this.downloadToFile(dir, videoId, videoFile),
          mimeType: "video/mp4",
          filename: `${videoId}.mp4`,
        },
      ],
      usage: {
        inputTokens: 0,
        outputTokens: 0,
      },
      model,
      seconds: mergedInput.seconds ? parseInt(mergedInput.seconds, 10) : DEFAULT_SECONDS,
    };
  }
}
