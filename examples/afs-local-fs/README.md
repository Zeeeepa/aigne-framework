# AFS SystemFS Example

<p align="center">
  <picture>
    <source srcset="https://raw.githubusercontent.com/AIGNE-io/aigne-framework/main/logo-dark.svg" media="(prefers-color-scheme: dark)">
    <source srcset="https://raw.githubusercontent.com/AIGNE-io/aigne-framework/main/logo.svg" media="(prefers-color-scheme: light)">
    <img src="https://raw.githubusercontent.com/AIGNE-io/aigne-framework/main/logo.svg" alt="AIGNE Logo" width="400" />
  </picture>
</p>

This example demonstrates how to create a chatbot that can interact with your local file system using the [AIGNE Framework](https://github.com/AIGNE-io/aigne-framework) and [AIGNE CLI](https://github.com/AIGNE-io/aigne-framework/blob/main/packages/cli/README.md). The example utilizes the `SystemFS` module to provide file system access to AI agents through the **AIGNE File System (AFS)** interface.

**AIGNE File System (AFS)** is a virtual file system abstraction that provides AI agents with unified access to various storage backends. For comprehensive documentation, see [AFS Documentation](../../afs/README.md).

## What You'll See

**User asks:** "What is AIGNE?"

**Behind the scenes:**
1. LLM calls `afs_search` ‚Üí searches all files for "AIGNE"
2. Finds `/modules/local-fs/docs/getting-started/what-is-aigne.md`
3. LLM calls `afs_read` ‚Üí reads the specific file
4. LLM presents: "AIGNE is a framework and runtime engine for building LLM-powered applications..."

**The power:** AI agents intelligently search your file system and retrieve exactly what's needed - no manual navigation required!

## Prerequisites

* [Node.js](https://nodejs.org) (>=20.0) and npm installed on your machine
* An [OpenAI API key](https://platform.openai.com/api-keys) for interacting with OpenAI's services
* Optional dependencies (if running the example from source code):
  * [Pnpm](https://pnpm.io) for package management
  * [Bun](https://bun.sh) for running unit tests & examples

## Quick Start (No Installation Required)

### Run the Example

```bash
export OPENAI_API_KEY=YOUR_OPENAI_API_KEY

# Mount AIGNE framework docs (clone first)
git clone https://github.com/AIGNE-io/aigne-framework
npx -y @aigne/example-afs-local-fs --path ./aigne-framework --chat

# Or mount any directory
npx -y @aigne/example-afs-local-fs --path ~/Documents --description "My Documents" --chat

# Ask a specific question
npx -y @aigne/example-afs-local-fs --path . --input "What is AIGNE?"
```

## See It In Action

Here's what happens when you ask "What is AIGNE?" with the framework docs mounted:

```
üë§ You: "What is AIGNE?"

ü§ñ Agent thinks: I should search the docs for information about AIGNE...
   ‚Üí Calls: afs_search(query: "AIGNE")

üìÅ Found 15 matching files:
   ‚Ä¢ docs/getting-started/what-is-aigne.md ‚≠ê (most relevant)
   ‚Ä¢ README.md
   ‚Ä¢ docs/core-concepts/overview.md
   ...

ü§ñ Agent thinks: Let me read the most relevant file...
   ‚Üí Calls: afs_read("docs/getting-started/what-is-aigne.md")

üìÑ File loaded (2.4 KB)

ü§ñ AI: "AIGNE is a framework and runtime engine for building LLM-powered
       applications and AI agents. It provides:

       ‚Ä¢ A unified Agentic File System (AFS) interface
       ‚Ä¢ Support for multiple LLM providers (OpenAI, Anthropic, etc.)
       ‚Ä¢ Tools for building autonomous agents
       ‚Ä¢ Integration with external services via MCP

       Would you like me to walk you through a quick-start tutorial, or
       would you prefer to see specific examples?"
```

**Key insight:** The agent intelligently searches, finds the right file, reads it, and synthesizes a helpful answer - all automatically!

### Connect to an AI Model

As an example, running `npx -y @aigne/example-afs-system-fs --path . --input "What files are in the current directory?"` requires an AI model. If this is your first run, you need to connect one.

![run example](./run-example.png)

- Connect via the official AIGNE Hub

Choose the first option and your browser will open the official AIGNE Hub page. Follow the prompts to complete the connection. If you're a new user, the system automatically grants 400,000 tokens for you to use.

![connect to official aigne hub](../images/connect-to-aigne-hub.png)

- Connect via a self-hosted AIGNE Hub

Choose the second option, enter the URL of your self-hosted AIGNE Hub, and follow the prompts to complete the connection. If you need to set up a self-hosted AIGNE Hub, visit the Blocklet Store to install and deploy it: [Blocklet Store](https://store.blocklet.dev/blocklets/z8ia3xzq2tMq8CRHfaXj1BTYJyYnEcHbqP8cJ?utm_source=www.arcblock.io&utm_medium=blog_link&utm_campaign=default&utm_content=store.blocklet.dev#:~:text=%F0%9F%9A%80%20Get%20Started%20in%20Minutes).

![connect to self hosted aigne hub](../images/connect-to-self-hosted-aigne-hub.png)

- Connect via a third-party model provider

Using OpenAI as an example, you can configure the provider's API key via environment variables. After configuration, run the example again:

```bash
export OPENAI_API_KEY="" # Set your OpenAI API key here
```
For more details on third-party model configuration (e.g., OpenAI, DeepSeek, Google Gemini), see [.env.local.example](./.env.local.example).

After configuration, run the example again.

### Debugging

The `aigne observe` command starts a local web server to monitor and analyze agent execution data. It provides a user-friendly interface to inspect traces, view detailed call information, and understand your agent‚Äôs behavior during runtime. This tool is essential for debugging, performance tuning, and gaining insight into how your agent processes information and interacts with tools and models.

Start the observation server.

![aigne-observe-execute](../images/aigne-observe-execute.png)

View a list of recent executions.

![aigne-observe-list](../images/aigne-observe-list.png)

## Installation

### Clone the Repository

```bash
git clone https://github.com/AIGNE-io/aigne-framework
```

### Install Dependencies

```bash
cd aigne-framework/examples/afs-local-fs

pnpm install
```



### Run the Example

```bash
# Run with your current directory
pnpm start --path .

# Run with a specific directory
pnpm start --path ~/Documents --description "My Documents"

# Run in interactive chat mode
pnpm start --path . --chat
```

## How It Works: 3 Simple Steps

### 1. Create LocalFS Module

```typescript
import { LocalFS } from "@aigne/afs-local-fs";

const localFS = new LocalFS({
  localPath: './aigne-framework',
  description: 'AIGNE framework documentation'
});
```

### 2. Mount It as an AFS Module

```typescript
import { AFS } from "@aigne/afs";
import { AFSHistory } from "@aigne/afs-history";

const afs = new AFS()
  .mount(new AFSHistory({ storage: { url: ":memory:" } }))
  .mount(localFS);  // Mounted at /modules/local-fs
```

### 3. Create an AI Agent

```typescript
import { AIAgent } from "@aigne/core";

const agent = AIAgent.from({
  instructions: "Help users find and read files from the local file system.",
  inputKey: "message",
  afs,  // Agent gets: afs_list, afs_read, afs_write, afs_search
});
```

**That's it!** The agent can now intelligently search and retrieve files from your local directory.

### What the Agent Can Do

- **`afs_list`** - List files and directories (with recursive depth control)
- **`afs_read`** - Read file contents and metadata
- **`afs_write`** - Create or update files
- **`afs_search`** - Fast full-text search using ripgrep (supports regex)

All operations are sandboxed to the mounted directory for safety.

## Try These Examples

```bash
# Mount AIGNE docs and ask questions
git clone https://github.com/AIGNE-io/aigne-framework
npx -y @aigne/example-afs-local-fs --path ./aigne-framework --input "What is AIGNE?"

# Ask about specific features
npx -y @aigne/example-afs-local-fs --path ./aigne-framework --input "How does AFS work?"

# Search your codebase
npx -y @aigne/example-afs-local-fs --path . --input "Find all TypeScript files with TODO comments"

# Interactive mode - ask follow-up questions
npx -y @aigne/example-afs-local-fs --path ~/Documents --chat
```

**In chat mode, try:**
- "What files are in this directory?"
- "Show me the README"
- "Search for 'authentication' in all files"
- "Find all Python files"
- "What does the config.json file contain?"

## Use Cases

### Documentation Chat
Mount your project docs and let users ask questions:
```typescript
const afs = new AFS()
  .mount(new LocalFS({ localPath: './docs', description: 'Project documentation' }));
// Users can now ask: "How do I configure authentication?"
```

### Codebase Analysis
Give AI agents access to your codebase:
```typescript
const afs = new AFS()
  .mount(new LocalFS({ localPath: './src', description: 'Source code' }));
// Agent can search, read, and explain code
```

### File Organization
Let AI help organize your files:
```typescript
const afs = new AFS()
  .mount(new LocalFS({ localPath: '~/Downloads', description: 'Downloads folder' }));
// Ask: "Find all PDFs from last week" or "Organize these files by type"
```

### Multi-Directory Access
Mount multiple directories simultaneously:
```typescript
const afs = new AFS()
  .mount("/docs", new LocalFS({ localPath: './docs' }))
  .mount("/src", new LocalFS({ localPath: './src' }))
  .mount("/tests", new LocalFS({ localPath: './tests' }));
// Agent can search across all mounted directories
```

## Related Examples

- [AFS Memory Example](../afs-memory/README.md) - Conversational memory with user profiles
- [AFS MCP Server Example](../afs-mcp-server/README.md) - Integration with MCP servers

## Related Packages

- [@aigne/afs](../../afs/README.md) - AFS core package
- [@aigne/afs-local-fs](../../afs/local-fs/README.md) - LocalFS module documentation

## TypeScript Support

This package includes full TypeScript type definitions.

## License

[MIT](../../LICENSE.md)
